This project involves training a custom Word2Vec model on a text dataset sourced from Kaggle or the web. After preprocessing and tokenizing the text, high-dimensional word embeddings are generated and reduced to 2D using PCA. These 2D vectors are then visualized using matplotlib to explore word relationships. Finally, the model is used to compute similarity between words based on their embeddings.
